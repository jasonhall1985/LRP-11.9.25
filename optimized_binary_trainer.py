#!/usr/bin/env python3
"""
Optimized Binary Cross-Demographic Trainer
Based on debug findings: simpler architecture, better learning rate, proper preprocessing
"""

import os
import csv
import cv2
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from pathlib import Path
import time
from collections import defaultdict

class OptimizedBinaryTrainer:
    def __init__(self):
        self.manifests_dir = Path("data/classifier training 20.9.25/binary_classification")
        self.output_dir = Path("optimized_binary_results")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Optimized configuration based on debug results
        self.batch_size = 6  # Balanced batch size
        self.max_epochs = 40
        self.learning_rate = 0.005  # Sweet spot between debug (0.01) and original (0.001)
        self.device = torch.device('cpu')
        
        # Success criteria (more realistic)
        self.target_train_acc = 85.0  # Achievable based on debug
        self.target_val_acc = 65.0    # Realistic cross-demographic target
        
        self.class_to_idx = {'doctor': 0, 'help': 1}
        
        print("üöÄ OPTIMIZED BINARY CROSS-DEMOGRAPHIC TRAINER")
        print("=" * 60)
        print("üí° Based on debug findings: Simpler architecture, better parameters")
        print(f"üéØ Targets: {self.target_train_acc}% training, {self.target_val_acc}% cross-demographic")
        
    def load_datasets(self):
        """Load datasets with optimized preprocessing."""
        print("\nüìã LOADING OPTIMIZED DATASETS")
        print("=" * 40)
        
        train_manifest = self.manifests_dir / "binary_train_manifest.csv"
        val_manifest = self.manifests_dir / "binary_validation_manifest.csv"
        
        self.train_dataset = OptimizedLipReadingDataset(train_manifest, self.class_to_idx)
        self.val_dataset = OptimizedLipReadingDataset(val_manifest, self.class_to_idx)
        
        print(f"üìä Training: {len(self.train_dataset)} videos")
        print(f"   Demographics: {self.train_dataset.get_demographics()}")
        print(f"   Classes: {self.train_dataset.get_class_distribution()}")
        
        print(f"üìä Validation: {len(self.val_dataset)} videos")
        print(f"   Demographics: {self.val_dataset.get_demographics()}")
        print(f"   Classes: {self.val_dataset.get_class_distribution()}")
        
        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)
        self.val_loader = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)
        
        # Verify zero demographic overlap
        train_demos = self.train_dataset.get_unique_demographics()
        val_demos = self.val_dataset.get_unique_demographics()
        
        print(f"‚úÖ Cross-demographic setup confirmed:")
        print(f"   Training: {train_demos}")
        print(f"   Validation: {val_demos}")
        
    def setup_training(self):
        """Setup optimized model and training components."""
        print("\nüèóÔ∏è  SETTING UP OPTIMIZED TRAINING")
        print("=" * 40)
        
        # Optimized model (balance between simple and complex)
        self.model = OptimizedBinaryModel().to(self.device)
        
        total_params = sum(p.numel() for p in self.model.parameters())
        print(f"üìä Model parameters: {total_params:,}")
        
        # Optimized optimizer and scheduler
        self.optimizer = optim.AdamW(
            self.model.parameters(), 
            lr=self.learning_rate, 
            weight_decay=0.005  # Reduced weight decay
        )
        
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='max', factor=0.7, patience=8  # More patient
        )
        
        self.criterion = nn.CrossEntropyLoss()
        
        # Training tracking
        self.train_losses = []
        self.train_accuracies = []
        self.val_losses = []
        self.val_accuracies = []
        self.best_val_acc = 0.0
        self.epochs_without_improvement = 0
        
        print(f"‚úÖ Optimized setup complete:")
        print(f"   Optimizer: AdamW (lr={self.learning_rate}, weight_decay=0.005)")
        print(f"   Scheduler: ReduceLROnPlateau (factor=0.7, patience=8)")
        
    def train_epoch(self):
        """Train one epoch with progress tracking."""
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (videos, labels) in enumerate(self.train_loader):
            videos, labels = videos.to(self.device), labels.to(self.device)
            
            self.optimizer.zero_grad()
            outputs = self.model(videos)
            loss = self.criterion(outputs, labels)
            loss.backward()
            
            # Gradient clipping for stability
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            # Progress logging
            if batch_idx % 2 == 0:
                acc = 100.0 * correct / total
                print(f"   Batch {batch_idx+1:2d}/{len(self.train_loader):2d} | "
                      f"Loss: {loss.item():.4f} | Acc: {acc:.1f}%")
        
        epoch_loss = total_loss / len(self.train_loader)
        epoch_acc = 100.0 * correct / total
        return epoch_loss, epoch_acc
    
    def validate_epoch(self):
        """Validate one epoch."""
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for videos, labels in self.val_loader:
                videos, labels = videos.to(self.device), labels.to(self.device)
                outputs = self.model(videos)
                loss = self.criterion(outputs, labels)
                
                total_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        epoch_loss = total_loss / len(self.val_loader)
        epoch_acc = 100.0 * correct / total
        return epoch_loss, epoch_acc
    
    def train_model(self):
        """Execute optimized training loop."""
        print("\nüéØ STARTING OPTIMIZED CROSS-DEMOGRAPHIC TRAINING")
        print("=" * 60)
        print(f"Target: {self.target_train_acc}% training, {self.target_val_acc}% cross-demographic validation")
        
        start_time = time.time()
        patience = 15  # Increased patience
        
        for epoch in range(1, self.max_epochs + 1):
            print(f"\nüìÖ Epoch {epoch:2d}/{self.max_epochs}")
            print("-" * 40)
            
            # Training
            train_loss, train_acc = self.train_epoch()
            
            # Validation
            val_loss, val_acc = self.validate_epoch()
            
            # Update tracking
            self.train_losses.append(train_loss)
            self.train_accuracies.append(train_acc)
            self.val_losses.append(val_loss)
            self.val_accuracies.append(val_acc)
            
            # Check for improvement
            is_best = val_acc > self.best_val_acc
            if is_best:
                self.best_val_acc = val_acc
                self.epochs_without_improvement = 0
                print(f"   üéâ NEW BEST VALIDATION: {val_acc:.1f}%")
            else:
                self.epochs_without_improvement += 1
            
            # Update learning rate
            self.scheduler.step(val_acc)
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # Epoch summary
            print(f"\nüìä Epoch {epoch} Summary:")
            print(f"   Train: {train_acc:.1f}% | Val: {val_acc:.1f}% | Best: {self.best_val_acc:.1f}%")
            print(f"   Learning Rate: {current_lr:.2e}")
            print(f"   Time: {time.time() - start_time:.1f}s")
            
            # Check success criteria
            if train_acc >= self.target_train_acc and val_acc >= self.target_val_acc:
                print(f"\nüéâ SUCCESS CRITERIA MET!")
                print(f"   ‚úÖ Training: {train_acc:.1f}% ‚â• {self.target_train_acc}%")
                print(f"   ‚úÖ Cross-demographic: {val_acc:.1f}% ‚â• {self.target_val_acc}%")
                success = True
                break
            
            # Early stopping
            if self.epochs_without_improvement >= patience:
                print(f"\n‚èπÔ∏è  Early stopping (patience: {patience})")
                success = False
                break
        else:
            success = train_acc >= self.target_train_acc and self.best_val_acc >= self.target_val_acc
        
        # Final results
        total_time = time.time() - start_time
        self.generate_final_report(total_time, success)
        return success
    
    def generate_final_report(self, training_time, success):
        """Generate final training report."""
        final_train_acc = self.train_accuracies[-1] if self.train_accuracies else 0
        final_val_acc = self.val_accuracies[-1] if self.val_accuracies else 0
        
        print(f"\nüéØ OPTIMIZED CROSS-DEMOGRAPHIC TRAINING COMPLETED")
        print("=" * 60)
        print(f"üìä Final Results:")
        print(f"   Final Training: {final_train_acc:.1f}%")
        print(f"   Final Validation: {final_val_acc:.1f}%")
        print(f"   Best Validation: {self.best_val_acc:.1f}%")
        print(f"   Training Time: {training_time:.1f}s")
        print(f"   Total Epochs: {len(self.train_accuracies)}")
        
        if success:
            print(f"\n‚úÖ PIPELINE VALIDATION SUCCESSFUL!")
            print(f"üöÄ Ready to proceed to full 7-class cross-demographic training")
        else:
            print(f"\n‚ö†Ô∏è  Pipeline validation incomplete but shows promise")
            print(f"üí° Consider: More epochs, data augmentation, or architecture tweaks")
        
        return success
    
    def run_complete_pipeline(self):
        """Execute complete optimized pipeline."""
        try:
            self.load_datasets()
            self.setup_training()
            success = self.train_model()
            return success
        except Exception as e:
            print(f"\n‚ùå OPTIMIZED TRAINING FAILED: {e}")
            raise

class OptimizedLipReadingDataset(Dataset):
    """Optimized dataset with better preprocessing."""
    
    def __init__(self, manifest_path, class_to_idx):
        self.class_to_idx = class_to_idx
        self.videos = []
        
        with open(manifest_path, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row['class'] in class_to_idx:
                    self.videos.append({
                        'path': row['video_path'],
                        'class': row['class'],
                        'class_idx': class_to_idx[row['class']],
                        'demographic_group': row['demographic_group']
                    })
    
    def __len__(self):
        return len(self.videos)
    
    def __getitem__(self, idx):
        video_info = self.videos[idx]
        frames = self._load_video_optimized(video_info['path'])
        
        # Optimized preprocessing
        frames_tensor = torch.from_numpy(frames).float() / 255.0
        frames_tensor = frames_tensor.unsqueeze(0)  # Add channel
        
        return frames_tensor, video_info['class_idx']
    
    def _load_video_optimized(self, video_path):
        """Optimized video loading - balance between simple and complex."""
        cap = cv2.VideoCapture(video_path)
        frames = []
        
        # Load 24 frames (compromise between 16 and 32)
        target_frames = 24
        frame_count = 0
        
        while frame_count < target_frames:
            ret, frame = cap.read()
            if not ret:
                break
            
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            # Moderate downsampling: 64x48 (compromise between 48x32 and 96x64)
            resized_frame = cv2.resize(gray_frame, (64, 48))
            frames.append(resized_frame)
            frame_count += 1
        
        cap.release()
        
        # Pad if needed
        while len(frames) < target_frames:
            frames.append(frames[-1] if frames else np.zeros((48, 64)))
        
        return np.array(frames[:target_frames])  # Shape: (24, 48, 64)
    
    def get_demographics(self):
        demographics = defaultdict(int)
        for video in self.videos:
            demographics[video['demographic_group']] += 1
        return dict(demographics)
    
    def get_class_distribution(self):
        classes = defaultdict(int)
        for video in self.videos:
            classes[video['class']] += 1
        return dict(classes)
    
    def get_unique_demographics(self):
        return set(video['demographic_group'] for video in self.videos)

class OptimizedBinaryModel(nn.Module):
    """Optimized model - balance between simple debug model and complex original."""
    
    def __init__(self):
        super(OptimizedBinaryModel, self).__init__()
        
        # Moderate 3D CNN architecture
        self.conv3d1 = nn.Conv3d(1, 32, kernel_size=(3, 3, 3), padding=1)
        self.bn3d1 = nn.BatchNorm3d(32)
        self.pool3d1 = nn.MaxPool3d(kernel_size=(1, 2, 2))  # Spatial only
        
        self.conv3d2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=1)
        self.bn3d2 = nn.BatchNorm3d(64)
        self.pool3d2 = nn.MaxPool3d(kernel_size=(2, 2, 2))  # Temporal + spatial
        
        self.conv3d3 = nn.Conv3d(64, 96, kernel_size=(3, 3, 3), padding=1)
        self.bn3d3 = nn.BatchNorm3d(96)
        self.pool3d3 = nn.MaxPool3d(kernel_size=(2, 2, 2))  # Temporal + spatial
        
        # Feature size: 96 * 6 * 6 * 8 = 27,648
        self.feature_size = 96 * 6 * 6 * 8
        
        # Moderate classifier
        self.dropout1 = nn.Dropout(0.4)
        self.fc1 = nn.Linear(self.feature_size, 256)
        self.dropout2 = nn.Dropout(0.3)
        self.fc2 = nn.Linear(256, 64)
        self.fc3 = nn.Linear(64, 2)
        
        print(f"üèóÔ∏è  Optimized Binary Model:")
        print(f"   - Input: (B, 1, 24, 48, 64)")
        print(f"   - Features: {self.feature_size:,}")
        print(f"   - Architecture: 3D CNN ‚Üí FC layers")
    
    def forward(self, x):
        # 3D CNN feature extraction
        x = F.relu(self.bn3d1(self.conv3d1(x)))
        x = self.pool3d1(x)
        
        x = F.relu(self.bn3d2(self.conv3d2(x)))
        x = self.pool3d2(x)
        
        x = F.relu(self.bn3d3(self.conv3d3(x)))
        x = self.pool3d3(x)
        
        # Flatten and classify
        x = x.view(x.size(0), -1)
        
        x = self.dropout1(x)
        x = F.relu(self.fc1(x))
        x = self.dropout2(x)
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        
        return x

def main():
    """Run optimized binary training."""
    print("üöÄ STARTING OPTIMIZED BINARY CROSS-DEMOGRAPHIC TRAINING")
    print("üí° Balanced approach based on debug insights")
    
    trainer = OptimizedBinaryTrainer()
    success = trainer.run_complete_pipeline()
    
    if success:
        print("\nüéâ PIPELINE VALIDATION SUCCESSFUL!")
        print("üöÄ Ready for full 7-class cross-demographic training!")
    else:
        print("\nüí° Pipeline shows promise - consider refinements")

if __name__ == "__main__":
    main()
