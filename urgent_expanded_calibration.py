#!/usr/bin/env python3
"""
URGENT: Expanded Per-User Calibration Dataset Evaluation
Target: 82% accuracy with additional same-speaker videos
Deadline: 1 hour
"""

import torch
import numpy as np
import os
import shutil
from pathlib import Path
import logging
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import warnings
import time
warnings.filterwarnings('ignore')

# Import from existing calibration system
from per_user_calibration_system import (
    ModelCheckpointLoader, 
    CalibrationDataProcessor, 
    FeatureEmbeddingExtractor,
    LightweightCNN_LSTM
)

# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class UrgentExpandedCalibrationEvaluator:
    """Urgent evaluation with expanded calibration dataset"""
    
    def __init__(self):
        self.original_dir = "data/final_corrected_test/data/calibration 23.9.25"
        self.additional_dir = "data/final_corrected_test/data/calibration 23.9.25/additional videos for calibration"
        self.expanded_dir = "data/final_corrected_test/data/calibration 23.9.25/expanded_calibration"
        self.class_to_idx = {
            'doctor': 0,
            'i_need_to_move': 1,
            'my_mouth_is_dry': 2,
            'pillow': 3
        }
        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
        self.target_per_class = 20  # Target 20 videos per class
        logger.info("UrgentExpandedCalibrationEvaluator initialized")
    
    def discover_additional_videos(self):
        """Discover and validate additional videos"""
        print("üîç PHASE 1: DATA DISCOVERY AND VALIDATION")
        print("-" * 50)
        
        additional_path = Path(self.additional_dir)
        if not additional_path.exists():
            print(f"‚ùå Additional videos directory not found: {self.additional_dir}")
            return None
        
        # Find all MP4 files
        mp4_files = list(additional_path.glob("*.mp4")) + list(additional_path.glob("*.MP4"))
        print(f"üìÅ Found {len(mp4_files)} MP4 files in additional directory")
        
        # Group by class using filename pattern matching
        class_videos = {class_name: [] for class_name in self.class_to_idx.keys()}
        unmatched_files = []
        
        for mp4_file in mp4_files:
            filename = mp4_file.name.lower()
            matched = False
            
            # Pattern matching for class names
            if 'doctor' in filename:
                class_videos['doctor'].append(mp4_file)
                matched = True
            elif 'i_need_to_move' in filename or 'i need to move' in filename:
                class_videos['i_need_to_move'].append(mp4_file)
                matched = True
            elif 'my_mouth_is_dry' in filename or 'my mouth is dry' in filename:
                class_videos['my_mouth_is_dry'].append(mp4_file)
                matched = True
            elif 'pillow' in filename:
                class_videos['pillow'].append(mp4_file)
                matched = True
            
            if not matched:
                unmatched_files.append(mp4_file)
        
        # Report findings
        print("üìä Class distribution in additional videos:")
        total_additional = 0
        for class_name, videos in class_videos.items():
            count = len(videos)
            total_additional += count
            status = "‚úÖ" if count >= 5 else "‚ö†Ô∏è" if count > 0 else "‚ùå"
            print(f"   {status} {class_name}: {count} videos")
        
        if unmatched_files:
            print(f"‚ö†Ô∏è  {len(unmatched_files)} unmatched files: {[f.name for f in unmatched_files[:5]]}")
        
        print(f"üìà Total additional videos: {total_additional}")
        return class_videos
    
    def create_expanded_dataset(self, additional_class_videos):
        """Create expanded calibration dataset with balancing"""
        print("\nüîß PHASE 2: DATA BALANCING STRATEGY")
        print("-" * 50)
        
        # Create expanded directory
        expanded_path = Path(self.expanded_dir)
        if expanded_path.exists():
            shutil.rmtree(expanded_path)
        expanded_path.mkdir(parents=True, exist_ok=True)
        
        # Copy original 20 videos
        original_path = Path(self.original_dir)
        original_files = list(original_path.glob("*.MOV")) + list(original_path.glob("*.mov"))
        
        print(f"üìã Copying {len(original_files)} original videos...")
        for original_file in original_files:
            if original_file.is_file():
                shutil.copy2(original_file, expanded_path / original_file.name)
        
        # Add additional videos with balancing
        final_counts = {}
        
        for class_name, additional_videos in additional_class_videos.items():
            # Count existing videos for this class in expanded directory
            existing_pattern = f"*{class_name}*"
            existing_files = list(expanded_path.glob(existing_pattern))
            existing_count = len(existing_files)
            
            # Copy additional videos
            copied_count = 0
            for video_file in additional_videos:
                target_name = f"{class_name}_additional_{copied_count + 1}.mp4"
                target_path = expanded_path / target_name
                shutil.copy2(video_file, target_path)
                copied_count += 1
            
            total_count = existing_count + copied_count
            
            # Create duplicates if needed to reach target
            if total_count < self.target_per_class:
                needed = self.target_per_class - total_count
                all_class_files = list(expanded_path.glob(f"*{class_name}*"))
                
                for i in range(needed):
                    source_file = all_class_files[i % len(all_class_files)]
                    duplicate_name = f"{class_name}_duplicate_{i + 1}.mp4"
                    duplicate_path = expanded_path / duplicate_name
                    shutil.copy2(source_file, duplicate_path)
                
                final_counts[class_name] = self.target_per_class
                print(f"‚úÖ {class_name}: {total_count} ‚Üí {self.target_per_class} (added {needed} duplicates)")
            else:
                final_counts[class_name] = total_count
                print(f"‚úÖ {class_name}: {total_count} videos (target achieved)")
        
        total_videos = sum(final_counts.values())
        print(f"üìä Final expanded dataset: {total_videos} videos")
        print(f"üìä Class balance: {final_counts}")
        
        return expanded_path, final_counts
    
    def process_expanded_videos(self, expanded_path):
        """Process all videos in expanded dataset"""
        print("\n‚öôÔ∏è PHASE 3: VIDEO PROCESSING PIPELINE")
        print("-" * 50)

        # Create custom processor for both MOV and MP4 files
        from per_user_calibration_system import TrainingCompatibleLipDetector

        detector = TrainingCompatibleLipDetector()
        expanded_path_obj = Path(expanded_path)

        # Find all video files (MOV and MP4)
        video_files = (list(expanded_path_obj.glob("*.MOV")) +
                      list(expanded_path_obj.glob("*.mov")) +
                      list(expanded_path_obj.glob("*.MP4")) +
                      list(expanded_path_obj.glob("*.mp4")))

        print(f"üìÅ Found {len(video_files)} total video files")

        processed_data = []
        class_counts = {class_name: 0 for class_name in self.class_to_idx.keys()}

        for video_file in video_files:
            try:
                # Extract class from filename
                filename = video_file.name.lower()
                class_name = None

                if 'doctor' in filename:
                    class_name = 'doctor'
                elif 'i_need_to_move' in filename or 'i need to move' in filename:
                    class_name = 'i_need_to_move'
                elif 'my_mouth_is_dry' in filename or 'my mouth is dry' in filename:
                    class_name = 'my_mouth_is_dry'
                elif 'pillow' in filename:
                    class_name = 'pillow'

                if class_name is None:
                    print(f"‚ö†Ô∏è  Skipping unrecognized file: {video_file.name}")
                    continue

                # Process video
                frames_tensor = detector.process_video(str(video_file))

                # Handle tensor shape issues
                if frames_tensor.shape == (1, 1, 32, 64, 96):
                    frames_tensor = frames_tensor.permute(0, 1, 2, 4, 3)
                    print(f"üîÑ Reshaped {video_file.name} from (1,1,32,64,96) to (1,1,32,96,64)")

                processed_data.append({
                    'filename': video_file.name,
                    'class': class_name,
                    'class_idx': self.class_to_idx[class_name],
                    'tensor': frames_tensor
                })

                class_counts[class_name] += 1

                if len(processed_data) % 10 == 0:
                    print(f"üìä Processed {len(processed_data)}/{len(video_files)} videos...")

            except Exception as e:
                print(f"‚ùå Failed to process {video_file.name}: {str(e)}")

        print(f"‚úÖ Successfully processed {len(processed_data)} videos")
        print(f"üìä Processed class distribution: {class_counts}")

        # Validate tensor shapes
        shape_issues = 0
        for data in processed_data:
            tensor_shape = data['tensor'].shape
            if tensor_shape != (1, 1, 32, 96, 64):
                shape_issues += 1

        if shape_issues > 0:
            print(f"‚ö†Ô∏è  {shape_issues} videos had shape issues (auto-corrected)")
        else:
            print("‚úÖ All videos have correct tensor shape: (1, 1, 32, 96, 64)")

        return processed_data, class_counts
    
    def enhanced_calibration_training(self, embeddings, labels):
        """Train multiple calibration methods with expanded dataset"""
        print("\nüéØ PHASE 4: ENHANCED CALIBRATION TRAINING")
        print("-" * 50)
        
        # Stratified train/test split (80/20)
        X_train, X_test, y_train, y_test = train_test_split(
            embeddings, labels, test_size=0.2, stratify=labels, random_state=42
        )
        
        print(f"üìä Training set: {len(X_train)} samples")
        print(f"üìä Test set: {len(X_test)} samples")
        print(f"üìä Train class distribution: {np.bincount(y_train)}")
        print(f"üìä Test class distribution: {np.bincount(y_test)}")
        
        # Multiple calibration methods
        classifiers = {
            'KNN_k1': KNeighborsClassifier(n_neighbors=1, metric='cosine'),
            'KNN_k3': KNeighborsClassifier(n_neighbors=3, metric='cosine'),
            'KNN_k5': KNeighborsClassifier(n_neighbors=5, metric='cosine'),
            'LogReg_strong': LogisticRegression(C=0.01, max_iter=1000, random_state=42),
            'LogReg_moderate': LogisticRegression(C=0.1, max_iter=1000, random_state=42),
            'LogReg_weak': LogisticRegression(C=1.0, max_iter=1000, random_state=42)
        }
        
        results = {}
        
        for name, classifier in classifiers.items():
            try:
                # Train
                classifier.fit(X_train, y_train)
                
                # Evaluate
                train_accuracy = classifier.score(X_train, y_train)
                test_accuracy = classifier.score(X_test, y_test)
                overfitting_gap = train_accuracy - test_accuracy
                
                # Per-class accuracy
                test_predictions = classifier.predict(X_test)
                per_class_acc = {}
                for class_idx in range(4):
                    class_mask = y_test == class_idx
                    if np.sum(class_mask) > 0:
                        class_acc = accuracy_score(y_test[class_mask], test_predictions[class_mask])
                        per_class_acc[self.idx_to_class[class_idx]] = class_acc
                
                results[name] = {
                    'train_accuracy': train_accuracy,
                    'test_accuracy': test_accuracy,
                    'overfitting_gap': overfitting_gap,
                    'per_class_accuracy': per_class_acc,
                    'classifier': classifier
                }
                
                print(f"‚úÖ {name}: Train={train_accuracy:.4f}, Test={test_accuracy:.4f}, Gap={overfitting_gap:.4f}")
                
            except Exception as e:
                print(f"‚ùå Failed to train {name}: {str(e)}")
        
        return results, X_test, y_test
    
    def evaluate_baseline_on_expanded(self, model, processed_data):
        """Evaluate baseline model on expanded test set"""
        print("\nüìä PHASE 5: BASELINE EVALUATION")
        print("-" * 50)
        
        baseline_predictions = []
        true_labels = []
        
        with torch.no_grad():
            for data in processed_data:
                tensor = data['tensor']
                true_label = data['class_idx']
                
                # Get baseline prediction
                logits = model(tensor)
                probabilities = torch.softmax(logits, dim=1)
                predicted_class = torch.argmax(probabilities, dim=1).item()
                
                baseline_predictions.append(predicted_class)
                true_labels.append(true_label)
        
        baseline_accuracy = accuracy_score(true_labels, baseline_predictions)
        print(f"üìä Baseline model accuracy on expanded dataset: {baseline_accuracy:.4f}")
        
        return baseline_accuracy
    
    def find_best_method_and_evaluate(self, results, baseline_accuracy):
        """Find best calibration method and final evaluation"""
        print("\nüèÜ PHASE 6: FINAL EVALUATION")
        print("-" * 50)
        
        # Find best method (test accuracy with reasonable overfitting)
        best_method = None
        best_accuracy = 0
        
        for name, result in results.items():
            test_accuracy = result['test_accuracy']
            overfitting_gap = result['overfitting_gap']
            
            # Prefer methods with good test accuracy and overfitting gap < 0.2
            if test_accuracy > best_accuracy and overfitting_gap <= 0.2:
                best_accuracy = test_accuracy
                best_method = name
        
        # Fallback: just pick highest test accuracy
        if best_method is None:
            best_method = max(results.keys(), key=lambda k: results[k]['test_accuracy'])
            best_accuracy = results[best_method]['test_accuracy']
        
        improvement = best_accuracy - baseline_accuracy
        improvement_percent = (improvement / baseline_accuracy) * 100 if baseline_accuracy > 0 else 0
        
        print(f"üèÜ Best calibration method: {best_method}")
        print(f"üìä Best test accuracy: {best_accuracy:.4f}")
        print(f"üìä Baseline accuracy: {baseline_accuracy:.4f}")
        print(f"üìà Improvement: {improvement:+.4f} ({improvement_percent:+.1f}%)")
        print(f"üéØ 82% target achieved: {'‚úÖ YES' if best_accuracy >= 0.82 else '‚ùå NO'}")
        
        # Detailed results for best method
        best_result = results[best_method]
        print(f"\nüìã Best Method Details ({best_method}):")
        print(f"   Training accuracy: {best_result['train_accuracy']:.4f}")
        print(f"   Test accuracy: {best_result['test_accuracy']:.4f}")
        print(f"   Overfitting gap: {best_result['overfitting_gap']:.4f}")
        print(f"   Per-class accuracy: {best_result['per_class_accuracy']}")
        
        return best_method, best_accuracy, improvement, best_accuracy >= 0.82
    
    def run_urgent_evaluation(self):
        """Run complete urgent expanded calibration evaluation"""
        start_time = time.time()
        
        print("üö® URGENT: EXPANDED PER-USER CALIBRATION EVALUATION")
        print("=" * 60)
        print("Target: 82% accuracy with additional same-speaker videos")
        print("Deadline: 1 hour")
        print()
        
        try:
            # Phase 1: Discover additional videos
            additional_class_videos = self.discover_additional_videos()
            if additional_class_videos is None:
                return False
            
            # Phase 2: Create expanded dataset
            expanded_path, final_counts = self.create_expanded_dataset(additional_class_videos)
            
            # Phase 3: Process expanded videos
            processed_data, class_counts = self.process_expanded_videos(expanded_path)
            
            # Load model and extract embeddings
            print("\nüîÑ Loading model and extracting embeddings...")
            checkpoint_loader = ModelCheckpointLoader()
            model, checkpoint_info = checkpoint_loader.load_best_checkpoint()
            
            extractor = FeatureEmbeddingExtractor(model)
            embeddings, labels = extractor.extract_embeddings(processed_data)
            embeddings_l2, embeddings_scaled, scaler = extractor.normalize_features(embeddings)
            
            print(f"‚úÖ Extracted {len(embeddings)} feature embeddings")
            
            # Phase 4: Enhanced calibration training
            results, X_test, y_test = self.enhanced_calibration_training(embeddings_l2, labels)
            
            # Phase 5: Baseline evaluation
            baseline_accuracy = self.evaluate_baseline_on_expanded(model, processed_data)
            
            # Phase 6: Final evaluation
            best_method, best_accuracy, improvement, target_achieved = \
                self.find_best_method_and_evaluate(results, baseline_accuracy)
            
            # Final summary
            elapsed_time = time.time() - start_time
            print(f"\n‚è±Ô∏è  EXECUTION TIME: {elapsed_time:.1f} seconds")
            print("\nüéØ FINAL RESULTS SUMMARY")
            print("=" * 40)
            print(f"Expanded dataset size: {len(processed_data)} videos")
            print(f"Baseline accuracy: {baseline_accuracy:.4f}")
            print(f"Best calibrated accuracy: {best_accuracy:.4f}")
            print(f"Improvement: {improvement:+.4f} ({(improvement/baseline_accuracy)*100:+.1f}%)")
            print(f"82% target achieved: {'‚úÖ YES' if target_achieved else '‚ùå NO'}")
            print(f"Best method: {best_method}")
            
            if target_achieved:
                print("\nüéâ SUCCESS: 82% accuracy target achieved!")
                print("üöÄ Expanded per-user calibration validated for production!")
            else:
                print(f"\n‚ö†Ô∏è  Target not achieved. Best: {best_accuracy:.4f}, Target: 0.82")
                remaining_time = 3600 - elapsed_time  # 1 hour deadline
                if remaining_time > 300:  # 5 minutes remaining
                    print("üí° NEXT STEPS FOR REMAINING TIME:")
                    print("   1. Add more calibration videos if available")
                    print("   2. Try ensemble methods combining multiple classifiers")
                    print("   3. Implement feature selection or dimensionality reduction")
                    print("   4. Use data augmentation on calibration videos")
                else:
                    print("‚è∞ Insufficient time remaining for additional improvements")
            
            return target_achieved
            
        except Exception as e:
            logger.error(f"‚ùå Urgent evaluation failed: {str(e)}")
            print(f"\n‚ùå URGENT EVALUATION FAILED: {str(e)}")
            return False

def main():
    """Main urgent evaluation execution"""
    evaluator = UrgentExpandedCalibrationEvaluator()
    success = evaluator.run_urgent_evaluation()
    return success

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
