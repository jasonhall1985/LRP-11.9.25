# ğŸ¯ Lip-Reading AI Demo - 75.9% Accuracy Model

Real-time lip-reading demonstration using the restored 75.9% validation accuracy checkpoint with 2.98M parameters.

## ğŸš€ Quick Start

### One-Tap Demo Launch
```bash
./start_demo.sh
```

This script will:
1. âœ… Get your LAN IP address
2. âœ… Update all frontend API URLs automatically  
3. âœ… Start backend server with 75.9% model
4. âœ… Verify health endpoints (laptop + iPhone)
5. âœ… Launch Expo in LAN mode (or tunnel fallback)
6. âœ… Display QR code for iPhone connection

### Manual Steps
```bash
# 1. Start backend
python demo_backend_server.py

# 2. Test health
curl http://YOUR_LAN_IP:5000/health

# 3. Open web demo
open web_demo.html

# 4. Start Expo (optional)
cd DemoLipreadingApp && npx expo start --lan
```

## ğŸ“± How to Frame Your Mouth (1-Minute Guide)

### ğŸ¯ Perfect Lip Placement

The model expects lips in a **96Ã—64 landscape rectangle**. Follow this guide:

#### âœ… Correct Positioning:
- **Lips centered** in the dashed rectangle overlay
- **Landscape orientation** (wider than tall)
- **Mouth fills 60-80%** of the guide box
- **Chin relatively still** during recording
- **Minimal head turning** - face the camera directly

#### âŒ Common Mistakes:
- Lips too high/low in frame
- Head tilted or turned sideways  
- Mouth too small in the guide box
- Moving head instead of just lips
- Poor lighting on mouth area

#### ğŸ’¡ Pro Tips:
- **"doctor"** typically gets highest accuracy (~80%)
- **Good lighting** on your face improves results
- **Clear mouth movements** with distinct lip shapes
- **3-second recordings** are optimal length
- **Keep chin still** - only move lips and jaw

### ğŸ¬ Recording Flow:
1. **Position face** so lips align with dashed rectangle
2. **Wait for 3-second countdown**
3. **Say phrase clearly** with exaggerated lip movements
4. **Keep head still** throughout recording
5. **Wait for AI processing** and confidence results

## ğŸ¯ Test Phrases & Expected Results

| Phrase | Expected Confidence | Notes |
|--------|-------------------|-------|
| **"doctor"** | High (75-85%) | Best accuracy, clear lip movements |
| **"pillow"** | Medium (50-70%) | Good accuracy, distinctive 'p' sound |
| **"my mouth is dry"** | Medium (45-65%) | Longer phrase, moderate accuracy |
| **"I need to move"** | Medium (40-60%) | Complex phrase, variable results |
| **Unclear/mumbled** | Low (<40%) | Should trigger low confidence |

## ğŸ”§ System Architecture

### Backend Server (`demo_backend_server.py`)
- **Model**: 75.9% validation accuracy (2.98M parameters)
- **Input**: 32 frames, 64Ã—96 grayscale, normalized [0,1]
- **Output**: Top-2 predictions with confidence scores
- **Formats**: MP4, MOV, AVI, WebM
- **Logging**: Detailed processing info + debug uploads

### Web Demo (`web_demo.html`)
- **Camera**: WebRTC MediaRecorder API
- **Guide**: 96Ã—64 lip placement overlay
- **Processing**: Real-time upload + inference
- **Results**: Confidence badges + debug info

### Expo App (`DemoLipreadingApp/`)
- **Platform**: React Native + Expo Go
- **Camera**: expo-camera with video recording
- **UI**: Professional iOS-style interface
- **Features**: Text-to-speech, confidence display

## ğŸ› Troubleshooting

### Connection Issues
- âœ… **Same WiFi**: Ensure iPhone and laptop on same network
- âœ… **Firewall**: Allow Python through macOS firewall
- âœ… **IP Address**: Verify LAN IP with `ifconfig`
- âœ… **Health Check**: Test `http://YOUR_IP:5000/health` in Safari

### Low Accuracy
- âœ… **Lip Placement**: Use the dashed rectangle guide
- âœ… **Lighting**: Ensure good lighting on face
- âœ… **Clarity**: Speak clearly with distinct mouth movements
- âœ… **Stillness**: Keep head still, only move lips

### No Frames Processed
- âœ… **Backend Running**: Check terminal for server logs
- âœ… **Correct URL**: Verify API_URL matches your LAN IP
- âœ… **File Upload**: Check debug_uploads/ folder for saved clips
- âœ… **CORS**: Backend should show CORS enabled

## ğŸ“Š Debug Information

### Backend Logs Show:
```
ğŸ¯ Received prediction request
ğŸ“ Received file: recording.webm
ğŸ“Š File size: 245.3 KB (251,187 bytes)
ğŸ” Debug copy saved: debug_uploads/latest_recording.webm
ğŸ¬ Processing video: recording.webm
ğŸ“Š Video info: 90 frames, 30.00 FPS, 3.00s duration
â±ï¸ Total processing time: 1.23s
ğŸ¯ Top predictions: doctor (0.847), pillow (0.098)
```

### Frontend Shows:
- **Backend Status**: Connected âœ…
- **Frames Processed**: Running count
- **Latency**: Upload + inference time
- **Debug Info**: Endpoint hit, timing details

## ğŸ“ File Structure

```
â”œâ”€â”€ demo_backend_server.py     # Flask server with 75.9% model
â”œâ”€â”€ web_demo.html             # Web-based demo with lip guide
â”œâ”€â”€ start_demo.sh             # One-tap startup script
â”œâ”€â”€ debug_uploads/            # Saved clips for inspection
â”œâ”€â”€ DemoLipreadingApp/        # Expo React Native app
â”‚   â””â”€â”€ App.js               # Main app with camera + UI
â””â”€â”€ README_DEMO.md           # This guide
```

## ğŸ¯ Success Metrics

- **High Confidence**: â‰¥75% (Green badge)
- **Medium Confidence**: 50-74% (Yellow badge)  
- **Low Confidence**: <50% (Red badge)
- **Processing Time**: ~1-2 seconds per clip
- **Frame Count**: Should show ~32 frames processed

---

**ğŸš€ Ready to test your lip-reading AI! Run `./start_demo.sh` and start recording.**
